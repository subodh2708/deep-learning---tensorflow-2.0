{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05-transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcIjfATdcyvreAhyRPagXL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subodh2708/deep-learning---tensorflow-2.0/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning in tensorflow part 2: fine tuning "
      ],
      "metadata": {
        "id": "gYnLoGuw2SIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "OGZme63G3yB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "7VWPxJO86UIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "kmBeQ3nA7zdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "I-sLDAI08q_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "XveB3VmQt-L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\""
      ],
      "metadata": {
        "id": "7bZKGyUAujMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory= train_dir,\n",
        "                                                                            image_size = IMG_SIZE,\n",
        "                                                                            label_mode = \"categorical\",\n",
        "                                                                            batch_size = BATCH_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory= test_dir,\n",
        "                                                               image_size=  IMG_SIZE,\n",
        "                                                               label_mode = \"categorical\",\n",
        "                                                               batch_size =  BATCH_SIZE)"
      ],
      "metadata": {
        "id": "CQMPkhBFYUNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_10_percent\n"
      ],
      "metadata": {
        "id": "cqQ1Om03aCO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "id": "NCZvJhL5baQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images , labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ],
      "metadata": {
        "id": "_gUyGERXcDh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 0 - Building a transfer learning model using Keras Funcional API"
      ],
      "metadata": {
        "id": "7iOjMRGrcVT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape= (224,224,3), name= \"input_layer\")\n",
        "x = base_model(inputs)\n",
        "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name = \"global_average_pooling_layer\")(x)\n",
        "print(f\" shape after GlobalAveragePooling2D: {x.shape}\")\n",
        "\n",
        "outputs = tf.keras.layers.Dense(10, activation = 'softmax', name = \"output_layers\")(x)\n",
        "\n",
        "model_0 = tf.keras.Model(inputs , outputs)\n",
        "\n",
        "model_0.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "history_10_percent = model_0.fit(train_data_10_percent,\n",
        "                                 epochs = 5,\n",
        "                                 steps_per_epoch = len(train_data_10_percent),\n",
        "                                 validation_data = test_data,\n",
        "                                 validation_steps = int(0.25 * len(test_data)),\n",
        "                                 callbacks = [create_tensorboard_callback(dir_name = \"transfer learning \",\n",
        "                                                                         experiment_name = \"10_percent_feature_extraction\")])"
      ],
      "metadata": {
        "id": "2YwGFOCBZkR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.evaluate(test_data)"
      ],
      "metadata": {
        "id": "-EpcNfdQ1FuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_number , layer in enumerate(base_model.layers):\n",
        "  print(layer_number,layer.name)"
      ],
      "metadata": {
        "id": "gwX6mmMx2YL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "id": "YEtQwwXL21YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.summary()"
      ],
      "metadata": {
        "id": "tSpCjTBH3RNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_10_percent)"
      ],
      "metadata": {
        "id": "5kXN-S1i3-sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a feature vector from a trained model"
      ],
      "metadata": {
        "id": "lcEOipn34aPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (1,4,4,3)\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"Random input shape: \\n {input_tensor} \\n \")\n",
        "\n",
        "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"2D global average pooled random tensor: \\n {global_average_pooled_tensor} \\n\")\n",
        "\n",
        "print(f\" shape of input tensor: {input_tensor.shape}\")\n",
        "print(f\"shape of global average pooled 2D tenor: {global_average_pooled_tensor.shape}\")"
      ],
      "metadata": {
        "id": "wx4nEpYE5Qtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_mean(input_tensor, axis = [1,2])"
      ],
      "metadata": {
        "id": "rXbk6DjF7O5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a series of experiment  on transfer learning"
      ],
      "metadata": {
        "id": "ku7kuhJ6-hlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting and preprocessing the data for model_1"
      ],
      "metadata": {
        "id": "Xre18b4kDD9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_1_percent.zip\")"
      ],
      "metadata": {
        "id": "zMp0D3-fAy_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"10_food_classes_1_percent/train\"\n",
        "test_dir = \"10_food_classes_1_percent/test\""
      ],
      "metadata": {
        "id": "oY2gygPzCND8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"10_food_classes_1_percent\")"
      ],
      "metadata": {
        "id": "j6NTjNPFCxXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224,224)\n",
        "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                           label_mode = 'categorical',\n",
        "                                                                           image_size = IMG_SIZE,\n",
        "                                                                           batch_size = BATCH_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode = 'categorical',\n",
        "                                                                image_size = IMG_SIZE,\n",
        "                                                                batch_size= BATCH_SIZE)"
      ],
      "metadata": {
        "id": "xFpofF9oD4BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "t-8pw6vdFUQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "metadata": {
        "id": "9H_UjVlXF_bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\"),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2),\n",
        "] , name = \"data_augmentation\")"
      ],
      "metadata": {
        "id": "q2CDfacWGqTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n",
        "target_class = random.choice(train_data_1_percent.class_names)\n",
        "target_dir = \"10_food_classes_1_percent/train/\" + target_class\n",
        "random_image = random.choice(os.listdir(target_dir))\n",
        "random_image_path = target_dir + '/' + random_image\n",
        "img = mpimg.imread(random_image_path)\n",
        "plt.imshow(img)\n",
        "plt.title(f\" original random image from {target_class}\")\n",
        "plt.axis(False)\n",
        "\n",
        "augmented_img = data_augmentation(img, training = True)\n",
        "plt.figure()\n",
        "plt.imshow((augmented_img)/255)\n",
        "plt.title(f\"Augmented Random image from class:{target_class}\")\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "y00nMxtUK1bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## model_1: feature transfer learning with 1% of data with data augmentation"
      ],
      "metadata": {
        "id": "f4ArVp5qLsv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224,224,3)"
      ],
      "metadata": {
        "id": "U1_7oTlPWWzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = False\n",
        "\n",
        "input = layers.Input(shape= input_shape, name = 'input_layers')\n",
        "\n",
        "x = data_augmentation(input)\n",
        "\n",
        "x = base_model(x , training = False)\n",
        "\n",
        "x = layers.GlobalAveragePooling2D(name = \"global_average_pooling_layer\")(x)\n",
        "\n",
        "outputs = layers.Dense(10, activation = 'softmax', name= 'output_layer')(x)\n",
        "\n",
        "model_1 = tf.keras.Model(input, outputs)\n",
        "\n",
        "model_1.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "history_1_percent = model_1.fit(train_data_1_percent,\n",
        "                                epochs = 5,\n",
        "                                steps_per_epoch = len(train_data_1_percent),\n",
        "                                validation_data = test_data,\n",
        "                                validation_steps = int(0.25 * len(test_data)),\n",
        "                                callbacks = [create_tensorboard_callback(dir_name = 'transfer_learning',\n",
        "                                                                         experiment_name = '1_percent_data_augment')])"
      ],
      "metadata": {
        "id": "hhezxM5SfsLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "id": "VvL8088UgMp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_1_percent_data_aug = model_1.evaluate(test_data)\n",
        "result_1_percent_data_aug"
      ],
      "metadata": {
        "id": "UE_eL43TLFCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_1_percent)"
      ],
      "metadata": {
        "id": "A28PMTV1LV29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 2 : feature extraction transfer learning model with 10% data with data augmentation"
      ],
      "metadata": {
        "id": "mfcy5UzuMS3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "id": "NPqpm505M6Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "FCYCSt93N3EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir_10_percent = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\""
      ],
      "metadata": {
        "id": "WF-OpvgvOcum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "lVJc6wusRO_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "IMG_SIZE = (224,224)\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_10_percent,\n",
        "                                                                            label_mode = \"categorical\",\n",
        "                                                                            image_size =  IMG_SIZE,\n",
        "                                                                            )\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode = 'categorical',\n",
        "                                                                image_size = IMG_SIZE)\n"
      ],
      "metadata": {
        "id": "CdWPv_pOPy-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "AqnZncTYQ4--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\"),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomRotation(0.2)\n",
        "],name = \"data_augmentation\")"
      ],
      "metadata": {
        "id": "-hvdOSlQSNyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224,224,3)\n",
        "\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape = input_shape, name = \"input_layers\")\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x,training = False)\n",
        "x = layers.GlobalAveragePooling2D(name = 'global_average_pooling_2D')(x)\n",
        "outputs = layers.Dense(10, activation = 'softmax', name = 'output_layer')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model_2.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "qjMotEubTnyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creating a model checkpoint callback"
      ],
      "metadata": {
        "id": "0OIi_4hNVqA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"ten_percent_model_checkpoints_weights/checkpoint.ckpt\""
      ],
      "metadata": {
        "id": "PrOZkfMVX3r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_path,\n",
        "                                                          save_weights_only = True,\n",
        "                                                          save_best_only = False,\n",
        "                                                          save_freq = 'epoch',\n",
        "                                                          verbose = 1)"
      ],
      "metadata": {
        "id": "7gbRFyvbZjNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_epochs = 5\n",
        "history_10_percent_data_aug = model_2.fit(train_data_10_percent,\n",
        "                                          epochs = initial_epochs,\n",
        "                                          validation_data = test_data,\n",
        "                                          validation_steps = int(0.25 * len(test_data)),\n",
        "                                          callbacks = [create_tensorboard_callback(dir_name = 'transfer_learning',\n",
        "                                                                                  experiment_name = \"10_percent_data_aug\"),\n",
        "                                                       checkpoint_callback])"
      ],
      "metadata": {
        "id": "O0jHD84uaoyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.evaluate(test_data)"
      ],
      "metadata": {
        "id": "-3V4X-N2c_Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_10_percent_data_aug =model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "d-khmD2jdzxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_10_percent_data_aug)"
      ],
      "metadata": {
        "id": "Ni6q-iVdd4sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loading in checkpoint"
      ],
      "metadata": {
        "id": "Jy035hkXeq5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "_XkAuYnb8bBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_weights_model_results = model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "u76jCfE5_VEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_10_percent_data_aug == loaded_weights_model_results"
      ],
      "metadata": {
        "id": "nWTVMTTBUzen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_10_percent_data_aug"
      ],
      "metadata": {
        "id": "V17UN0ThWubC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_weights_model_results"
      ],
      "metadata": {
        "id": "6AmslRwrXiO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#model 3: Fine-tuning on existing model on 10% of the data"
      ],
      "metadata": {
        "id": "FUC4kaddaN9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.layers"
      ],
      "metadata": {
        "id": "k_19iDkEa88x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_2.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "rQuYA3X-fSHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,layer in enumerate(model_2.layers[2].layers):\n",
        "  print(i, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "DnW5yaX5fo7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model_2.layers[2].trainable_variables))"
      ],
      "metadata": {
        "id": "XNd3eCKRgXAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-10]:\n",
        "  layer.trainable = False\n",
        "\n",
        "model_2.compile(loss = 'categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.Adam(lr = 0.0001),\n",
        "                metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "eYp_ZJbihpcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i , layer in enumerate(model_2.layers[2].layers):\n",
        "  print(i , layer.name , layer.trainable)"
      ],
      "metadata": {
        "id": "eyNM0CXhlV-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model_2.trainable_variables))"
      ],
      "metadata": {
        "id": "f9ij2QGclpLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = initial_epochs + 5\n",
        "\n",
        "history_fine_10_percent_data_aug = model_2.fit(train_data_10_percent,\n",
        "                                                epochs = fine_tune_epochs,\n",
        "                                                validation_data = test_data,\n",
        "                                                validation_steps = int(0.25 * len(test_data)),\n",
        "                                                initial_epoch = history_10_percent_data_aug.epoch[-1],\n",
        "                                                callbacks = [create_tensorboard_callback(dir_name='transfer_learning',\n",
        "                                                                                         experiment_name= '10_percent_fine_tune_last_10')])"
      ],
      "metadata": {
        "id": "wlQSgnKpjXHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_fine_tune_10_percent = model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "CtOBLfoR_a2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_10_percent_data_aug"
      ],
      "metadata": {
        "id": "5CFoJI_eEGCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_fine_10_percent_data_aug)"
      ],
      "metadata": {
        "id": "HqNUoNBVENQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_history(original_history, new_history, initial_epochs=5):\n",
        "  \"\"\"\n",
        "  Compare two tensorflow history objects\n",
        "\n",
        "  \"\"\"\n",
        "  \n",
        "  acc = original_history.history['accuracy']\n",
        "  loss = original_history.history['loss']\n",
        "\n",
        "  val_acc = original_history.history['val_accuracy']\n",
        "  val_loss = original_history.history['val_loss']\n",
        "\n",
        "  total_acc = acc + new_history.history['accuracy']\n",
        "  total_loss = loss + new_history.history['loss']\n",
        "\n",
        "  total_val_acc = acc + new_history.history['val_accuracy']\n",
        "  total_val_loss = loss + new_history.history['val_loss']\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(total_acc, label= 'training accuracy')\n",
        "  plt.plot(total_val_acc, label = 'val accuracy')\n",
        "  plt.plot([initial_epochs-1, initial_epochs-1],plt.ylim(),label='start fine tuning')\n",
        "  plt.legend(loc= \"lower right\")\n",
        "  plt.title(\"Training and Validation accuracy\")\n",
        "\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.subplot(2,1,1)\n",
        "  plt.plot(total_loss, label= 'training loss')\n",
        "  plt.plot(total_val_loss, label = 'val loss')\n",
        "  plt.plot([initial_epochs-1, initial_epochs-1],plt.ylim(),label='start fine tuning')\n",
        "  plt.legend(loc= \"upper right\")\n",
        "  plt.title(\"Training and Validation loss\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ibwpxTMOFQx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_history(history_10_percent_data_aug,\n",
        "                history_fine_10_percent_data_aug,\n",
        "                initial_epochs = 5)"
      ],
      "metadata": {
        "id": "_CTX7PnLJAUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model 4 : fine tuning an existing model with all the data"
      ],
      "metadata": {
        "id": "vim8oFiwJUzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "unzip_data(\"10_food_classes_all_data.zip\")"
      ],
      "metadata": {
        "id": "w0ntnghpMFqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir_all_data = \"10_food_classes_all_data/train\"\n",
        "test_dir = \"10_food_classes_all_data/test\""
      ],
      "metadata": {
        "id": "LxsHlUj0MRMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(\"10_food_classes_all_data\")"
      ],
      "metadata": {
        "id": "SbiNAVozMynA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224,224)\n",
        "\n",
        "train_data_10_classes_full = tf.keras.preprocessing.image_dataset_from_directory(train_dir_all_data,\n",
        "                                                                                 label_mode = 'categorical',\n",
        "                                                                                 image_size = IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode = 'categorical',\n",
        "                                                                image_size = IMG_SIZE)"
      ],
      "metadata": {
        "id": "02_Bw3FGM-tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "RdPSe16pOKe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_fine_tune_10_percent"
      ],
      "metadata": {
        "id": "pHaDCsJaOuMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "s8NjzCnTO16K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "VgeIuWISPqyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_10_percent_data_aug"
      ],
      "metadata": {
        "id": "uaXIZX_lP-vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_number , layer in enumerate(model_2.layers):\n",
        "  print(layer_number, layer.name,layer.trainable)"
      ],
      "metadata": {
        "id": "5C7ee6SDQFCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "IaJ2Kjw8RdRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_epochs = initial_epochs + 5\n",
        "\n",
        "history_fine_10_classes_full = model_2.fit(train_data_10_classes_full,\n",
        "                                           epochs = fine_tune_epochs,\n",
        "                                           validation_data = test_data,\n",
        "                                           validation_steps = int(0.25 * len(test_data)),\n",
        "                                           initial_epoch = history_10_percent_data_aug.epoch[-1],\n",
        "                                           callbacks= [create_tensorboard_callback(dir_name=\"transfer_learning\",\n",
        "                                                                                   experiment_name = 'full_10_classes_fine_tune_last_10')])"
      ],
      "metadata": {
        "id": "BHLCFJq8USiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !nvidia-smi"
      ],
      "metadata": {
        "id": "GdL08eKiWFAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_fine_tune_all_data = model_2.evaluate(test_data)"
      ],
      "metadata": {
        "id": "LOfGl4bad4lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How did fine-tuning go with more data?\n",
        "compare_history(original_history=history_10_percent_data_aug,\n",
        "                 new_history=history_fine_10_classes_full,\n",
        "                 initial_epochs=5)"
      ],
      "metadata": {
        "id": "SGzP-Q5QegBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viewing our experiment on Tensorboeard"
      ],
      "metadata": {
        "id": "9_kpRyU_ffJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./transfer_learning \\\n",
        "  --name \"Transfer learning experiments\" \\\n",
        "  --description \"A series of different transfer learning experiments with varying amounts of data and fine-tuning\" \\\n",
        "  --one_shot # exits the uploader when upload has finished"
      ],
      "metadata": {
        "id": "NfKudwyWgUes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zj5BKkcQiSBw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}